{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Masking, Embedding\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "File \u001b[0;32m~/phd/venvs/softwater/lib/python3.8/site-packages/keras/__init__.py:20\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "File \u001b[0;32m~/phd/venvs/softwater/lib/python3.8/site-packages/keras/distribute/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras' Distribution Strategy library.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sidecar_evaluator\n",
      "File \u001b[0;32m~/phd/venvs/softwater/lib/python3.8/site-packages/keras/distribute/sidecar_evaluator.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Python module for evaluation loop.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Masking, Embedding\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import pickle\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_norm = pd.read_csv(\"data/all_df_basic_norm.csv\")\n",
    "norm_bounds = pd.read_csv(\"data/norm_bounds_basic.csv\")\n",
    "all_df = pd.read_csv(\"data/all_df_basic.csv\")\n",
    "all_df_shuffled, all_df_norm_shuffled = sklearn.utils.shuffle(all_df, all_df_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Segmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_data(data, x_labels, y_labels, split_factor=0.8):\n",
    "    x_data = data[x_labels]\n",
    "    y_data = data[y_labels]\n",
    "\n",
    "    x_dim = len(x_labels)\n",
    "    y_dim = len(y_labels)\n",
    "\n",
    "    split = int(split_factor * len(x_data))\n",
    "\n",
    "    x_train = x_data[:split]\n",
    "    y_train = y_data[:split]\n",
    "\n",
    "    x_test = x_data[split:]\n",
    "    y_test = y_data[split:]\n",
    "    return x_train, y_train, x_test, y_test, x_dim, y_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learned Forward Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk_x_labels = [\"M1-PL\", \"M1-PR\", \"M2-PL\", \"M2-PR\",\n",
    "            \"M1-AL-IN-ACT\", \"M1-AR-IN-ACT\", \"M2-AL-IN-ACT\", \"M2-AR-IN-ACT\",\n",
    "            \"M1-AL-OUT\", \"M1-AR-OUT\", \"M2-AL-OUT\", \"M2-AR-OUT\"]\n",
    "lookback = 3\n",
    "new_x_labels = []\n",
    "for i in range(lookback):\n",
    "    for l in fk_x_labels:\n",
    "        new_x_labels.append(l + str(i))\n",
    "fk_x_labels += new_x_labels\n",
    "\n",
    "fk_y_labels = [\"M1X\", \"M1Y\", \"M2X\", \"M2Y\", \"M3X\", \"M3Y\",\n",
    "            \"M4X\", \"M4Y\", \"M5X\", \"M5Y\", \"M6X\", \"M6Y\",\n",
    "            \"M7X\", \"M7Y\", \"M8X\", \"M8Y\", \"M9X\", \"M9Y\",\n",
    "            \"M10X\", \"M10Y\"]\n",
    "\n",
    "fk_x_train, fk_y_train, fk_x_test, fk_y_test, fk_x_dim, fk_y_dim = segment_data(all_df_norm_shuffled, fk_x_labels, fk_y_labels, split_factor=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmodel = Sequential()\n",
    "fmodel.add(Dense(128, input_dim=fk_x_dim, activation='relu'))\n",
    "fmodel.add(Dropout(0.2))\n",
    "fmodel.add(Dense(64, activation='relu'))\n",
    "fmodel.add(Dropout(0.2))\n",
    "fmodel.add(Dense(32, activation='relu'))\n",
    "fmodel.add(Dropout(0.2))\n",
    "fmodel.add(Dense(16, activation='relu'))\n",
    "fmodel.add(Dropout(0.2))\n",
    "fmodel.add(Dense(y_dim, activation='relu'))\n",
    "\n",
    "fmodel.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "fmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historyf = fmodel.fit(fk_x_train, fk_y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = fmodel.evaluate(fk_x_test, fk_y_test)\n",
    "print('Loss: %.8f, Accuracy: %.2f' % (loss, (accuracy*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learned Inverse Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ik_x_labels = [\"M1X\", \"M1Y\", \"M2X\", \"M2Y\", \"M3X\", \"M3Y\",\n",
    "            \"M4X\", \"M4Y\", \"M5X\", \"M5Y\", \"M6X\", \"M6Y\",\n",
    "            \"M7X\", \"M7Y\", \"M8X\", \"M8Y\", \"M9X\", \"M9Y\",\n",
    "            \"M10X\", \"M10Y\"]\n",
    "ik_y_labels = [\"M1-PL\", \"M1-PR\", \"M2-PL\", \"M2-PR\"]\n",
    "\n",
    "ik_x_train, ik_y_train, ik_x_test, ik_y_test, ik_x_dim, ik_y_dim = segment_data(all_df_norm_shuffled, ik_x_labels, ik_y_labels, split_factor=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel = Sequential()\n",
    "bmodel.add(Dense(128, input_dim=ik_x_dim, activation='relu'))\n",
    "bmodel.add(Dropout(0.2))\n",
    "bmodel.add(Dense(64, activation='relu'))\n",
    "bmodel.add(Dropout(0.2))\n",
    "bmodel.add(Dense(32, activation='relu'))\n",
    "bmodel.add(Dropout(0.2))\n",
    "bmodel.add(Dense(16, activation='relu'))\n",
    "bmodel.add(Dropout(0.2))\n",
    "bmodel.add(Dense(y_dim, activation='relu'))\n",
    "\n",
    "bmodel.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "bmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historyb = bmodel.fit(ik_x_train, ik_y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = bmodel.evaluate(ik_x_test, ik_y_test)\n",
    "print('Loss: %.8f, Accuracy: %.2f' % (loss, (accuracy*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plot(historyf, historyb):\n",
    "    plt.plot(historyf.history[\"loss\"], label=\"Forward Kinematics Model\")\n",
    "    plt.plot(historyb.history[\"loss\"], label=\"Inverse Kinematics Model\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss (mse)\")\n",
    "    plt.title(\"Training Loss for Kinematics Models\")\n",
    "    # plt.savefig(\"data/training_backward.png\")\n",
    "history_plot(historyf, historyb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(data, labels):\n",
    "    ndata = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        d = data[idx]\n",
    "        min_val = norm_bounds.loc[0, label]\n",
    "        max_val = norm_bounds.loc[1, label]\n",
    "        rescaled_d = (d * (max_val - min_val)) + min_val\n",
    "        ndata.append(rescaled_d)\n",
    "    return np.array(ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = len(x_test)\n",
    "def evaluate_markers(idx=(0,num_tests-1,1)):\n",
    "    index = x_test.index[idx]\n",
    "    x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "    y_pred = fmodel.predict(x_select)\n",
    "    cp = rescale(y_pred[0], y_labels)\n",
    "    ct = all_df.loc[index, y_labels].to_numpy()\n",
    "    \n",
    "    xp = [0]\n",
    "    xt = [0]\n",
    "    yp = [0]\n",
    "    yt = [0]\n",
    "    \n",
    "    for i in range(len(cp)):\n",
    "        if i%2 == 0:\n",
    "            xp.append(cp[i])\n",
    "            xt.append(ct[i])\n",
    "        else:\n",
    "            yp.append(cp[i])\n",
    "            yt.append(ct[i])\n",
    "    \n",
    "    plt.plot(xt, yt, \"-o\", label=\"actual\")\n",
    "    plt.plot(xp, yp, \"-o\", label=\"predicted\")\n",
    "    plt.xlim([-20,20])\n",
    "    plt.ylim([-1,39])\n",
    "    plt.xlabel(\"x (cm)\")\n",
    "    plt.ylabel(\"y (cm)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Predicted Markers vs. Actual Markers\")\n",
    "    plt.show()\n",
    "        \n",
    "interact(evaluate_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmodel.save(\"/Volumes/Flash/basic_bmodel/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = len(x_test)\n",
    "def evaluate_markers(idx=(0,num_tests-1,1)):\n",
    "    index = x_test.index[idx]\n",
    "    x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "    print(x_select)\n",
    "    print(x_select.shape)\n",
    "    y_pred = bmodel.predict(x_select)\n",
    "    pp = rescale(y_pred[0], y_labels)\n",
    "    pt = all_df.loc[index, y_labels].to_numpy()\n",
    "    print(pp)\n",
    "    print(pt)\n",
    "    plt.plot([1,2], pt[0:2], \"-o\", label=\"actual M1\", color=\"C0\")\n",
    "    plt.plot([3,4], pt[2:4], \"-x\", label=\"actual M2\", color=\"C0\")\n",
    "    plt.plot([1,2], pp[0:2], \"-o\", label=\"predicted M1\", color=\"C1\")\n",
    "    plt.plot([3,4], pp[2:4], \"-x\", label=\"predicted M2\", color=\"C1\")\n",
    "    plt.ylim([95,120])\n",
    "    plt.xlim([0.5,4.5])\n",
    "    plt.xticks([1,2,3,4], [\"P_1,1\", \"P_1,2\", \"P_2,1\", \"P_2,2\"])\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Pressure Sensor\")\n",
    "    plt.ylabel(\"Pressure Value (kPa)\")\n",
    "    plt.show()\n",
    "        \n",
    "interact(evaluate_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = len(x_test)\n",
    "def evaluate_polynomial(idx=(0,num_tests-1,1)):\n",
    "    index = x_test.index[idx]\n",
    "    x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "    p_pred = pmodel.predict(x_select)\n",
    "    pp = rescale(p_pred[0], p_labels)\n",
    "    pt = all_df.loc[index, p_labels].to_numpy()\n",
    "    \n",
    "    ap = np.flip(pp[:-1])\n",
    "    dp = pp[-1]\n",
    "    at = np.flip(pt[:-1])\n",
    "    dt = pt[-1]\n",
    "    \n",
    "    polyp = np.poly1d(ap)\n",
    "    polyt = np.poly1d(at)\n",
    "    \n",
    "    yp = np.linspace(0, dp)\n",
    "    xp = polyp(yp)\n",
    "    \n",
    "    yt = np.linspace(0, dt)\n",
    "    xt = polyt(yt)\n",
    "    \n",
    "    \n",
    "    plt.plot(xt, yt, label=\"actual\")\n",
    "    plt.plot(xp, yp, label=\"predicted\")\n",
    "    plt.xlim([-20,20])\n",
    "    plt.ylim([-1,39])\n",
    "    plt.xlabel(\"x (cm)\")\n",
    "    plt.ylabel(\"y (cm)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Predicted Markers vs. Actual Markers\")\n",
    "    plt.show()\n",
    "        \n",
    "interact(evaluate_polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for idx in range(len(x_test)):\n",
    "    index = x_test.index[idx]\n",
    "    x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "    y_pred = bmodel.predict(x_select)\n",
    "    y_pred = rescale(y_pred[0], y_labels)\n",
    "    y_select = all_df.loc[index, y_labels].to_numpy()\n",
    "    diff = (y_pred - y_select)\n",
    "    mse = (diff * diff).sum() / len(y_labels)\n",
    "    rmse = math.sqrt(mse)\n",
    "    errors.append((rmse, index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.sort()\n",
    "print(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = len(x_test)\n",
    "def evaluate_sort_markers(idx=(0,num_tests-1,1)):\n",
    "    index = errors[idx][1]\n",
    "    err = errors[idx][0]\n",
    "    x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "    y_pred = fmodel.predict(x_select)\n",
    "    cp = rescale(y_pred[0], y_labels)\n",
    "    ct = all_df.loc[index, y_labels].to_numpy()\n",
    "    \n",
    "    xp = [0]\n",
    "    xt = [0]\n",
    "    yp = [0]\n",
    "    yt = [0]\n",
    "    \n",
    "    for i in range(len(cp)):\n",
    "        if i%2 == 0:\n",
    "            xp.append(cp[i])\n",
    "            xt.append(ct[i])\n",
    "        else:\n",
    "            yp.append(cp[i])\n",
    "            yt.append(ct[i])\n",
    "    \n",
    "    plt.plot(xt, yt, \"-o\", label=\"actual\")\n",
    "    plt.plot(xp, yp, \"-o\", label=\"predicted\")\n",
    "    plt.xlim([-20,20])\n",
    "    plt.ylim([-1,39])\n",
    "    plt.xlabel(\"x (cm)\")\n",
    "    plt.ylabel(\"y (cm)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Predicted Markers vs. Actual Markers. RMSE: \" + str(round(err,5)) + \"cm\")\n",
    "    plt.show()\n",
    "        \n",
    "interact(evaluate_sort_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_errors = []\n",
    "for e in errors:\n",
    "    just_errors.append(e[0])\n",
    "plt.hist(just_errors, bins=30)\n",
    "plt.title(\"Histogram of Root Mean Squared Error for Forward Model\")\n",
    "plt.ylim([0,170])\n",
    "plt.ylabel(\"Number of Predictions\")\n",
    "plt.xlabel(\"Root Mean Squared Error (cm)\")\n",
    "plt.savefig(\"data/forward_error_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_index = 9\n",
    "data_index = 570\n",
    "for idx, e in enumerate(errors):\n",
    "    index = errors[idx][1]\n",
    "    file_index_temp = all_df.loc[index, \"file_index\"]\n",
    "    data_index_temp = all_df.loc[index, \"data_index\"]\n",
    "    if file_index_temp == file_index and data_index_temp == data_index:\n",
    "        break\n",
    "#idx = 1157\n",
    "index = errors[idx][1]\n",
    "err = errors[idx][0]\n",
    "print(index)\n",
    "x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "y_pred = fmodel.predict(x_select)\n",
    "cp = rescale(y_pred[0], y_labels)\n",
    "ct = all_df.loc[index, y_labels].to_numpy()\n",
    "\n",
    "xp = [0]\n",
    "xt = [0]\n",
    "yp = [0]\n",
    "yt = [0]\n",
    "\n",
    "for i in range(len(cp)):\n",
    "    if i%2 == 0:\n",
    "        xp.append(cp[i])\n",
    "        xt.append(ct[i])\n",
    "    else:\n",
    "        yp.append(cp[i])\n",
    "        yt.append(ct[i])\n",
    "\n",
    "plt.plot(xt, yt, \"-o\", label=\"actual\")\n",
    "plt.plot(xp, yp, \"-o\", label=\"predicted\")\n",
    "plt.xlim([-20,20])\n",
    "plt.ylim([-1,39])\n",
    "plt.xlabel(\"x (cm)\")\n",
    "plt.ylabel(\"y (cm)\")\n",
    "plt.legend()\n",
    "plt.title(\"Predicted Markers vs. Actual Markers. RMSE: \" + str(round(err,5)) + \"cm\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "file_index = all_df.loc[index, \"file_index\"]\n",
    "data_index = all_df.loc[index, \"data_index\"]\n",
    "fname = \"data/good\" + str(file_index) + \"_\" + str(data_index) + \"_2.png\"\n",
    "print(fname)\n",
    "plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests = len(x_test)\n",
    "def evaluate_sort_pressures(idx=(0,num_tests-1,1)):\n",
    "    index = errors[idx][1]\n",
    "    err = errors[idx][0]\n",
    "    x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "    y_pred = bmodel.predict(x_select)\n",
    "    pp = rescale(y_pred[0], y_labels)\n",
    "    pt = all_df.loc[index, y_labels].to_numpy()\n",
    "    print(pp)\n",
    "    print(pt)\n",
    "    plt.plot([1,2], pt[0:2], \"-o\", label=\"actual M1\", color=\"C0\")\n",
    "    plt.plot([3,4], pt[2:4], \"-x\", label=\"actual M2\", color=\"C0\")\n",
    "    plt.plot([1,2], pp[0:2], \"-o\", label=\"predicted M1\", color=\"C1\")\n",
    "    plt.plot([3,4], pp[2:4], \"-x\", label=\"predicted M2\", color=\"C1\")\n",
    "    plt.ylim([95,120])\n",
    "    plt.xlim([0.5,4.5])\n",
    "    plt.xticks([1,2,3,4], [\"P_1,1\", \"P_1,2\", \"P_2,1\", \"P_2,2\"])\n",
    "    plt.xlabel(\"Pressure Sensor\")\n",
    "    plt.ylabel(\"Pressure Value (kPa)\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Predicted Pressures vs. Actual Pressures. RMSE: \" + str(round(err,3)) + \"kPa\")\n",
    "    plt.show()\n",
    "        \n",
    "interact(evaluate_sort_pressures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_index = 9\n",
    "# data_index = 570\n",
    "# for idx, e in enumerate(errors):\n",
    "#     index = errors[idx][1]\n",
    "#     file_index_temp = all_df.loc[index, \"file_index\"]\n",
    "#     data_index_temp = all_df.loc[index, \"data_index\"]\n",
    "#     if file_index_temp == file_index and data_index_temp == data_index:\n",
    "#         break\n",
    "idx = 1177\n",
    "print(idx)\n",
    "index = errors[idx][1]\n",
    "err = errors[idx][0]\n",
    "print(index)\n",
    "x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "y_pred = bmodel.predict(x_select)\n",
    "pp = rescale(y_pred[0], y_labels)\n",
    "pt = all_df.loc[index, y_labels].to_numpy()\n",
    "print(pp)\n",
    "print(pt)\n",
    "plt.plot([1,2], pt[0:2], \"-o\", label=\"actual M1\", color=\"C0\")\n",
    "plt.plot([3,4], pt[2:4], \"-x\", label=\"actual M2\", color=\"C0\")\n",
    "plt.plot([1,2], pp[0:2], \"-o\", label=\"predicted M1\", color=\"C1\")\n",
    "plt.plot([3,4], pp[2:4], \"-x\", label=\"predicted M2\", color=\"C1\")\n",
    "plt.ylim([95,120])\n",
    "plt.xlim([0.5,4.5])\n",
    "plt.xticks([1,2,3,4], [\"P_1,1\", \"P_1,2\", \"P_2,1\", \"P_2,2\"])\n",
    "plt.xlabel(\"Pressure Sensor\")\n",
    "plt.ylabel(\"Pressure Value (kPa)\")\n",
    "plt.legend()\n",
    "plt.title(\"Predicted Pressures vs. Actual Pressures. RMSE: \" + str(round(err,3)) + \"kPa\")\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "file_index = all_df.loc[index, \"file_index\"]\n",
    "data_index = all_df.loc[index, \"data_index\"]\n",
    "fname = \"data_pressures/bad\" + str(file_index) + \"_\" + str(data_index) + \".png\"\n",
    "print(fname)\n",
    "plt.savefig(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_errors = []\n",
    "for e in errors:\n",
    "    just_errors.append(e[0])\n",
    "plt.hist(just_errors, bins=30)\n",
    "plt.title(\"Histogram of Root Mean Squared Error for Backward Model\")\n",
    "plt.ylim([0,170])\n",
    "plt.ylabel(\"Number of predictions\")\n",
    "plt.xlabel(\"Root Mean Squared Error (kPa)\")\n",
    "plt.savefig(\"data/backward_error_histogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
