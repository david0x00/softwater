{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order of files\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext1\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext2\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext3\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext4\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext1\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext2\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext3\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext4\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve1\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_headers = [\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext1\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext2\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext3\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext4\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext1\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext2\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext3\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext4\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve1\",\n",
    "#                 \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve2\"]\n",
    "\n",
    "file_headers = [\"/Volumes/Flash/combined_data/far_right_up_and_back\",\n",
    "                \"/Volumes/Flash/combined_data/far_left_up_and_back\",\n",
    "                \"/Volumes/Flash/combined_data/up_and_back3\",\n",
    "                \"/Volumes/Flash/combined_data/sweep1\",\n",
    "                \"/Volumes/Flash/combined_data/sweep2\",\n",
    "                \"/Volumes/Flash/combined_data/random\",\n",
    "                \"/Volumes/Flash/combined_data/module1_fullext1\",\n",
    "                \"/Volumes/Flash/combined_data/module1_fullext2\",\n",
    "                \"/Volumes/Flash/combined_data/module1_fullext3\",\n",
    "                \"/Volumes/Flash/combined_data/module1_fullext4\",\n",
    "                \"/Volumes/Flash/combined_data/module2_fullext1\",\n",
    "                \"/Volumes/Flash/combined_data/module2_fullext2\",\n",
    "                \"/Volumes/Flash/combined_data/module2_fullext3\",\n",
    "                \"/Volumes/Flash/combined_data/module2_fullext4\",\n",
    "                \"/Volumes/Flash/combined_data/s_curve1\",\n",
    "                \"/Volumes/Flash/combined_data/s_curve1_part2\",\n",
    "                \"/Volumes/Flash/combined_data/s_curve2\",\n",
    "                \"/Volumes/Flash/combined_data/s_curve2_part2\"]\n",
    "\n",
    "CSV_SFX = \".csv\"\n",
    "MARKERS_SFX = \"_markers\"\n",
    "POLY_SFX = \"_poly\"\n",
    "M10Y = \"M10Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poly_df_list = []\n",
    "marker_df_list = []\n",
    "data_df_list = []\n",
    "idx_df_list = []\n",
    "idx_file_df_list = []\n",
    "data_idx_df_list = []\n",
    "\n",
    "running_idx = 0\n",
    "end_idx = []\n",
    "\n",
    "for file_i, header in enumerate(file_headers):\n",
    "    data_file = header + CSV_SFX\n",
    "    marker_file = header + MARKERS_SFX + CSV_SFX\n",
    "    #poly_file = header + POLY_SFX + CSV_SFX\n",
    "    \n",
    "    data_df = pd.read_csv(data_file)\n",
    "    marker_df = pd.read_csv(marker_file)\n",
    "    #poly_df = pd.read_csv(poly_file)\n",
    "    \n",
    "    idx_array = running_idx+data_df.index.values\n",
    "    idx_df = pd.DataFrame(idx_array, columns=['global_index'])\n",
    "    end_idx.append(idx_array[-1])\n",
    "    running_idx = idx_array[-1] + 1   \n",
    "\n",
    "    idx_file_array = np.zeros(data_df.shape[0], dtype=int) + file_i\n",
    "    idx_file_df = pd.DataFrame(idx_file_array, columns=['file_index'])\n",
    "    \n",
    "    data_idx_array = data_df.index.values\n",
    "    data_idx_df = pd.DataFrame(data_idx_array, columns=['data_index'])\n",
    "    \n",
    "#     zero_indices = list(marker_df[marker_df[M10Y] == 0].index)\n",
    "#     print(marker_df)\n",
    "#     print(zero_indices)\n",
    "    \n",
    "#     data_df = data_df.drop(data_df.index[zero_indices])\n",
    "#     marker_df = marker_df.drop(marker_df.index[zero_indices])\n",
    "#     #poly_df = poly_df.drop(poly_df.index[zero_indices])\n",
    "#     idx_df = idx_df.drop(idx_df.index[zero_indices])\n",
    "#     idx_file_df = idx_file_df.drop(idx_file_df.index[zero_indices])\n",
    "#     data_idx_df = data_idx_df.drop(data_idx_df.index[zero_indices])\n",
    "    #print(marker_df)\n",
    "    data_df_list.append(data_df)\n",
    "    marker_df_list.append(marker_df)\n",
    "    #poly_df_list.append(poly_df)\n",
    "    idx_df_list.append(idx_df)\n",
    "    idx_file_df_list.append(idx_file_df)\n",
    "    data_idx_df_list.append(data_idx_df)\n",
    "\n",
    "total_data_df = pd.concat(data_df_list).reset_index(drop=True)\n",
    "total_marker_df = pd.concat(marker_df_list).reset_index(drop=True)\n",
    "#total_poly_df = pd.concat(poly_df_list).reset_index(drop=True)\n",
    "total_idx_df = pd.concat(idx_df_list).reset_index(drop=True)\n",
    "total_idx_file_df = pd.concat(idx_file_df_list).reset_index(drop=True)\n",
    "total_data_idx_df = pd.concat(data_idx_df_list).reset_index(drop=True)\n",
    "\n",
    "global_cont_idx_array = np.arange(total_data_df.shape[0], dtype=int)\n",
    "total_global_cont_idx_df = pd.DataFrame(global_cont_idx_array, columns=['global_cont1_index'])\n",
    "\n",
    "diff1_arr = total_data_df[\"M1-PL\"] - total_data_df[\"M1-PR\"] #left minus right\n",
    "diff2_arr = total_data_df[\"M2-PL\"] - total_data_df[\"M2-PR\"]\n",
    "total_data_df[\"M1-Diff\"] = diff1_arr\n",
    "total_data_df[\"M2-Diff\"] = diff2_arr\n",
    "\n",
    "m1_al_in_act = total_data_df[\"M1-AL-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "m1_ar_in_act = total_data_df[\"M1-AR-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "m2_al_in_act = total_data_df[\"M2-AL-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "m2_ar_in_act = total_data_df[\"M2-AR-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "\n",
    "total_data_df[\"M1-AL-IN-ACT\"] = m1_al_in_act\n",
    "total_data_df[\"M1-AR-IN-ACT\"] = m1_ar_in_act\n",
    "total_data_df[\"M2-AL-IN-ACT\"] = m2_al_in_act\n",
    "total_data_df[\"M2-AR-IN-ACT\"] = m2_ar_in_act\n",
    "\n",
    "training_data_list = [total_data_df, total_marker_df, total_idx_df, total_idx_file_df, total_data_idx_df, total_global_cont_idx_df]\n",
    "all_df = pd.concat(training_data_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(df, idx_col):\n",
    "    return df.groupby(df[idx_col].diff().ne(1).cumsum()).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_columns = [\n",
    "\"TIME\",\n",
    "\"M1-PL\",\n",
    "\"M1-PR\",\n",
    "\"M2-PL\",\n",
    "\"M2-PR\",\n",
    "\"M1-AL-IN\",\n",
    "\"M1-AL-OUT\",\n",
    "\"M1-AR-IN\",\n",
    "\"M1-AR-OUT\",\n",
    "\"M2-AL-IN\",\n",
    "\"M2-AL-OUT\",\n",
    "\"M2-AR-IN\",\n",
    "\"M2-AR-OUT\",\n",
    "\"PUMP\",\n",
    "\"GATE\",\n",
    "\"M1-Diff\",\n",
    "\"M2-Diff\",\n",
    "\"M1-AL-IN-ACT\",\n",
    "\"M1-AR-IN-ACT\",\n",
    "\"M2-AL-IN-ACT\",\n",
    "\"M2-AR-IN-ACT\",\n",
    "\"global_index\",\n",
    "\"file_index\",\n",
    "\"data_index\",\n",
    "\"global_cont1_index\"]\n",
    "\n",
    "lookback = 3\n",
    "stride = 7\n",
    "threshold = lookback * stride\n",
    "\n",
    "fresh_arr = np.zeros(all_df.shape[0], dtype=int)\n",
    "for i in range(lookback):\n",
    "    for col in lookback_columns:\n",
    "        fresh_df = pd.DataFrame(fresh_arr, columns=[col + str(i)])\n",
    "        all_df = pd.concat([all_df, fresh_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_groups = get_groups(all_df, \"data_index\")\n",
    "for dg in data_groups:\n",
    "    start_idx = data_groups[dg][0]\n",
    "    for idx in data_groups[dg]:\n",
    "        if (idx - start_idx) >= threshold:\n",
    "            for i in range(lookback):\n",
    "                new_lookback_columns = []\n",
    "                for colname in lookback_columns:\n",
    "                    new_lookback_columns.append(colname + str(i))\n",
    "                back_idx = idx - (stride*(i+1))\n",
    "                back_data = all_df.loc[back_idx, lookback_columns]\n",
    "                all_df.loc[idx, new_lookback_columns] = back_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          TIME    M1-PL    M1-PR    M2-PL    M2-PR  M1-AL-IN  M1-AL-OUT  \\\n",
      "0        0.159  101.328  100.797  100.803  100.834         0          0   \n",
      "1        0.661  101.328  100.797  100.809  100.834         0          0   \n",
      "2        1.230  101.328  100.797  100.809  100.828         0          0   \n",
      "3        1.740  101.328  100.797  100.803  100.828         0          0   \n",
      "4        2.233  101.328  100.797  100.809  100.834         0          0   \n",
      "...        ...      ...      ...      ...      ...       ...        ...   \n",
      "11731  476.739  100.628   99.740  100.653  100.872         0          0   \n",
      "11732  477.201  100.703   99.796  100.665  100.934         0          0   \n",
      "11733  477.602  100.703   99.790  100.665  100.940         0          0   \n",
      "11734  478.005  100.709   99.796  100.672  100.947         0          0   \n",
      "11735  478.405  100.709   99.796  100.665  100.940         0          0   \n",
      "\n",
      "       M1-AR-IN  M1-AR-OUT  M2-AL-IN  ...       M9X        M9Y  M9T      M10X  \\\n",
      "0             0          0         0  ...  0.658373  21.640504    0  0.694949   \n",
      "1             0          0         0  ...  0.658373  21.622039    0  0.713238   \n",
      "2             0          0         0  ...  0.640085  21.622039    0  0.703077   \n",
      "3             0          0         0  ...  0.640085  21.677433    0  0.694949   \n",
      "4             0          0         0  ...  0.621797  21.658969    0  0.694949   \n",
      "...         ...        ...       ...  ...       ...        ...  ...       ...   \n",
      "11731         0          1         0  ... -2.139713  22.769481    0 -2.688357   \n",
      "11732         0          0         0  ... -2.121425  22.751017    0 -2.670069   \n",
      "11733         0          0         0  ... -2.121425  22.769481    0 -2.670069   \n",
      "11734         0          0         0  ... -2.121425  22.769481    0 -2.670069   \n",
      "11735         0          0         0  ... -2.121425  22.751017    0 -2.670069   \n",
      "\n",
      "            M10Y  M10T  global_index  file_index  data_index  \\\n",
      "0      24.539445     0             0           0           0   \n",
      "1      24.520981     0             1           0           1   \n",
      "2      24.520981     0             2           0           2   \n",
      "3      24.520981     0             3           0           3   \n",
      "4      24.520981     0             4           0           4   \n",
      "...          ...   ...           ...         ...         ...   \n",
      "11731  25.816139     0         11731          17         734   \n",
      "11732  25.797675     0         11732          17         735   \n",
      "11733  25.797675     0         11733          17         736   \n",
      "11734  25.797675     0         11734          17         737   \n",
      "11735  25.797675     0         11735          17         738   \n",
      "\n",
      "       global_cont1_index  \n",
      "0                       0  \n",
      "1                       1  \n",
      "2                       2  \n",
      "3                       3  \n",
      "4                       4  \n",
      "...                   ...  \n",
      "11731               11731  \n",
      "11732               11732  \n",
      "11733               11733  \n",
      "11734               11734  \n",
      "11735               11735  \n",
      "\n",
      "[11736 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084]\n"
     ]
    }
   ],
   "source": [
    "zero_indices = list(all_df[all_df[\"TIME0\"] == 0].index)\n",
    "print(zero_indices)\n",
    "all_df = all_df.drop(all_df.index[zero_indices]).reset_index(drop=True)\n",
    "\n",
    "global_cont2_idx_array = np.arange(all_df.shape[0], dtype=int)\n",
    "total_global_cont2_idx_df = pd.DataFrame(global_cont2_idx_array, columns=['global_cont2_index'])\n",
    "all_df = pd.concat([all_df, total_global_cont2_idx_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"data/all_data_organized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'3a0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '3a0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m poly_heads \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3a0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3a1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3a2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3a3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4a0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4a1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4a2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4a3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4a4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5a0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5a1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5a2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5a3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5a4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5a5\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m poly_heads:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m p \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, min: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mall_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, max: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(all_df[p]\u001b[38;5;241m.\u001b[39mmax()))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:3506\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3506\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3508\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '3a0'"
     ]
    }
   ],
   "source": [
    "poly_heads = [\"3a0\",\"3a1\",\"3a2\",\"3a3\",\"4a0\",\"4a1\",\"4a2\",\"4a3\",\"4a4\",\"5a0\",\"5a1\",\"5a2\",\"5a3\",\"5a4\",\"5a5\"]\n",
    "for p in poly_heads:\n",
    "    print(\"head: \" + p + \", min: \" + str(all_df[p].min()) + \", max: \" + str(all_df[p].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX_min = -15\n",
    "MX_max = 15\n",
    "MY_min = 0\n",
    "MY_max = 40\n",
    "\n",
    "P_min = 95\n",
    "P_max = 121\n",
    "\n",
    "P_diff_min = -26\n",
    "P_diff_max = 26\n",
    "\n",
    "# d_min = 20\n",
    "# d_max = 40\n",
    "\n",
    "# a0_min = -0.019\n",
    "# a0_max = 0.014\n",
    "\n",
    "# a1_min = -0.3\n",
    "# a1_max = 0.22\n",
    "\n",
    "# a2_min = -0.11\n",
    "# a2_max = 0.17\n",
    "\n",
    "# a3_min = -0.027\n",
    "# a3_max = 0.016\n",
    "\n",
    "# a4_min = -0.0007\n",
    "# a4_max = 0.0014\n",
    "\n",
    "# a5_min = -0.000023\n",
    "# a5_max = 0.0000085\n",
    "\n",
    "norm_bounds = pd.DataFrame()\n",
    "for i in range(11):\n",
    "    norm_bounds[\"M\" + str(i) + \"X\"] = [MX_min, MX_max]\n",
    "    norm_bounds[\"M\" + str(i) + \"Y\"] = [MY_min, MY_max]\n",
    "\n",
    "# for i in range(3):\n",
    "#     norm_bounds[str(i+3) + \"a0\"] = [a0_min, a0_max]\n",
    "# for i in range(3):\n",
    "#     norm_bounds[str(i+3) + \"a1\"] = [a1_min, a1_max]\n",
    "# for i in range(3):\n",
    "#     norm_bounds[str(i+3) + \"a2\"] = [a2_min, a2_max]\n",
    "# for i in range(3):\n",
    "#     norm_bounds[str(i+3) + \"a3\"] = [a3_min, a3_max]\n",
    "# for i in range(2):\n",
    "#     norm_bounds[str(i+4) + \"a4\"] = [a4_min, a4_max]\n",
    "# norm_bounds[\"5a5\"] = [a5_min, a5_max]\n",
    "# norm_bounds[\"d\"] = [d_min, d_max]\n",
    "\n",
    "norm_bounds[\"M1-PL\"] = [P_min, P_max]\n",
    "norm_bounds[\"M1-PR\"] = [P_min, P_max]\n",
    "norm_bounds[\"M2-PL\"] = [P_min, P_max]\n",
    "norm_bounds[\"M2-PR\"] = [P_min, P_max]\n",
    "norm_bounds[\"M1-Diff\"] = [P_diff_min, P_diff_max]\n",
    "norm_bounds[\"M2-Diff\"] = [P_diff_min, P_diff_max]\n",
    "for i in range(lookback):\n",
    "    norm_bounds[\"M1-PL\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M1-PR\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M2-PL\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M2-PR\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M1-Diff\" + str(i)] = [P_diff_min, P_diff_max]\n",
    "    norm_bounds[\"M2-Diff\" + str(i)] = [P_diff_min, P_diff_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_bounds.to_csv(\"data/norm_bounds_basic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_norm = all_df.copy()\n",
    "for c in norm_bounds:\n",
    "    min_val = norm_bounds.loc[0,c]\n",
    "    max_val = norm_bounds.loc[1,c]\n",
    "    all_df_norm[c] = (all_df_norm[c] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_norm.to_csv(\"data/all_df_basic_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
