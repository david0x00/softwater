{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Masking, Embedding\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order of files\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext1\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext2\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext3\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext4\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext1\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext2\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext3\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext4\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve1\",\n",
    "\n",
    "\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_headers = [\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext1\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext2\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext3\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext4\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext1\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext2\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext3\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext4\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve1\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve2\"]\n",
    "\n",
    "CSV_SFX = \".csv\"\n",
    "MARKERS_SFX = \"_markers\"\n",
    "POLY_SFX = \"_poly\"\n",
    "M10Y = \"M10Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_df_list = []\n",
    "marker_df_list = []\n",
    "data_df_list = []\n",
    "idx_df_list = []\n",
    "idx_file_df_list = []\n",
    "data_idx_df_list = []\n",
    "\n",
    "running_idx = 0\n",
    "end_idx = []\n",
    "\n",
    "for file_i, header in enumerate(file_headers):\n",
    "    data_file = header + CSV_SFX\n",
    "    marker_file = header + MARKERS_SFX + CSV_SFX\n",
    "    poly_file = header + POLY_SFX + CSV_SFX\n",
    "    \n",
    "    data_df = pd.read_csv(data_file)\n",
    "    marker_df = pd.read_csv(marker_file)\n",
    "    poly_df = pd.read_csv(poly_file)\n",
    "    \n",
    "    idx_array = running_idx+data_df.index.values\n",
    "    idx_df = pd.DataFrame(idx_array, columns=['global_index'])\n",
    "    end_idx.append(idx_array[-1])\n",
    "    running_idx = idx_array[-1] + 1   \n",
    "\n",
    "    idx_file_array = np.zeros(data_df.shape[0], dtype=int) + file_i\n",
    "    idx_file_df = pd.DataFrame(idx_file_array, columns=['file_index'])\n",
    "    \n",
    "    data_idx_array = data_df.index.values\n",
    "    data_idx_df = pd.DataFrame(data_idx_array, columns=['data_index'])\n",
    "    \n",
    "    zero_indices = list(marker_df[marker_df[M10Y] == 0].index)\n",
    "    \n",
    "    data_df = data_df.drop(data_df.index[zero_indices])\n",
    "    marker_df = marker_df.drop(marker_df.index[zero_indices])\n",
    "    poly_df = poly_df.drop(poly_df.index[zero_indices])\n",
    "    idx_df = idx_df.drop(idx_df.index[zero_indices])\n",
    "    idx_file_df = idx_file_df.drop(idx_file_df.index[zero_indices])\n",
    "    data_idx_df = data_idx_df.drop(data_idx_df.index[zero_indices])\n",
    "    \n",
    "    data_df_list.append(data_df)\n",
    "    marker_df_list.append(marker_df)\n",
    "    poly_df_list.append(poly_df)\n",
    "    idx_df_list.append(idx_df)\n",
    "    idx_file_df_list.append(idx_file_df)\n",
    "    data_idx_df_list.append(data_idx_df)\n",
    "\n",
    "total_data_df = pd.concat(data_df_list).reset_index(drop=True)\n",
    "total_marker_df = pd.concat(marker_df_list).reset_index(drop=True)\n",
    "total_poly_df = pd.concat(poly_df_list).reset_index(drop=True)\n",
    "total_idx_df = pd.concat(idx_df_list).reset_index(drop=True)\n",
    "total_idx_file_df = pd.concat(idx_file_df_list).reset_index(drop=True)\n",
    "total_data_idx_df = pd.concat(data_idx_df_list).reset_index(drop=True)\n",
    "\n",
    "global_cont_idx_array = np.arange(total_data_df.shape[0], dtype=int)\n",
    "total_global_cont_idx_df = pd.DataFrame(global_cont_idx_array, columns=['global_cont1_index'])\n",
    "\n",
    "diff1_arr = total_data_df[\"M1-PL\"] - total_data_df[\"M1-PR\"] #left minus right\n",
    "diff2_arr = total_data_df[\"M2-PL\"] - total_data_df[\"M2-PR\"]\n",
    "total_data_df[\"M1-Diff\"] = diff1_arr\n",
    "total_data_df[\"M2-Diff\"] = diff2_arr\n",
    "\n",
    "m1_al_in_act = total_data_df[\"M1-AL-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "m1_ar_in_act = total_data_df[\"M1-AR-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "m2_al_in_act = total_data_df[\"M2-AL-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "m2_ar_in_act = total_data_df[\"M2-AR-IN\"] * total_data_df[\"PUMP\"] * total_data_df[\"GATE\"]\n",
    "\n",
    "total_data_df[\"M1-AL-IN-ACT\"] = m1_al_in_act\n",
    "total_data_df[\"M1-AR-IN-ACT\"] = m1_ar_in_act\n",
    "total_data_df[\"M2-AL-IN-ACT\"] = m2_al_in_act\n",
    "total_data_df[\"M2-AR-IN-ACT\"] = m2_ar_in_act\n",
    "\n",
    "training_data_list = [total_data_df, total_marker_df, total_poly_df, total_idx_df, total_idx_file_df, total_data_idx_df, total_global_cont_idx_df]\n",
    "all_df = pd.concat(training_data_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_groups(df, idx_col):\n",
    "    return df.groupby(df[idx_col].diff().ne(1).cumsum()).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_columns = [\n",
    "\"TIME\",\n",
    "\"M1-PL\",\n",
    "\"M1-PR\",\n",
    "\"M2-PL\",\n",
    "\"M2-PR\",\n",
    "\"M1-AL-IN\",\n",
    "\"M1-AL-OUT\",\n",
    "\"M1-AR-IN\",\n",
    "\"M1-AR-OUT\",\n",
    "\"M2-AL-IN\",\n",
    "\"M2-AL-OUT\",\n",
    "\"M2-AR-IN\",\n",
    "\"M2-AR-OUT\",\n",
    "\"PUMP\",\n",
    "\"GATE\",\n",
    "\"M1-Diff\",\n",
    "\"M2-Diff\",\n",
    "\"M1-AL-IN-ACT\",\n",
    "\"M1-AR-IN-ACT\",\n",
    "\"M2-AL-IN-ACT\",\n",
    "\"M2-AR-IN-ACT\",\n",
    "\"global_index\",\n",
    "\"file_index\",\n",
    "\"data_index\",\n",
    "\"global_cont1_index\"]\n",
    "\n",
    "lookback = 3\n",
    "stride = 7\n",
    "threshold = lookback * stride\n",
    "\n",
    "fresh_arr = np.zeros(all_df.shape[0], dtype=int)\n",
    "for i in range(lookback):\n",
    "    for col in lookback_columns:\n",
    "        fresh_df = pd.DataFrame(fresh_arr, columns=[col + str(i)])\n",
    "        all_df = pd.concat([all_df, fresh_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_groups = get_groups(all_df, \"data_index\")\n",
    "for dg in data_groups:\n",
    "    start_idx = data_groups[dg][0]\n",
    "    for idx in data_groups[dg]:\n",
    "        if (idx - start_idx) >= threshold:\n",
    "            for i in range(lookback):\n",
    "                new_lookback_columns = []\n",
    "                for colname in lookback_columns:\n",
    "                    new_lookback_columns.append(colname + str(i))\n",
    "                back_idx = idx - (stride*(i+1))\n",
    "                back_data = all_df.loc[back_idx, lookback_columns]\n",
    "                all_df.loc[idx, new_lookback_columns] = back_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_indices = list(all_df[all_df[\"TIME0\"] == 0].index)\n",
    "all_df = all_df.drop(all_df.index[zero_indices]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cont2_idx_array = np.arange(all_df.shape[0], dtype=int)\n",
    "total_global_cont2_idx_df = pd.DataFrame(global_cont2_idx_array, columns=['global_cont2_index'])\n",
    "all_df = pd.concat([all_df, total_global_cont2_idx_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"data/all_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: 3a0, min: -0.0188569649744513, max: 0.0136491122035742\n",
      "head: 3a1, min: -0.2969584332449708, max: 0.2149356146482047\n",
      "head: 3a2, min: -0.1098694624879628, max: 0.165398793648979\n",
      "head: 3a3, min: -0.0264902036799419, max: 0.0150428129201573\n",
      "head: 4a0, min: -0.0188569649744513, max: 0.0136491122035742\n",
      "head: 4a1, min: -0.2969584332449708, max: 0.2149356146482047\n",
      "head: 4a2, min: -0.1098694624879628, max: 0.165398793648979\n",
      "head: 4a3, min: -0.0264902036799419, max: 0.0150428129201573\n",
      "head: 4a4, min: -0.0006287992882555, max: 0.0013178262928751\n",
      "head: 5a0, min: -0.0188569649744513, max: 0.0136491122035742\n",
      "head: 5a1, min: -0.2969584332449708, max: 0.2149356146482047\n",
      "head: 5a2, min: -0.1098694624879628, max: 0.165398793648979\n",
      "head: 5a3, min: -0.0264902036799419, max: 0.0150428129201573\n",
      "head: 5a4, min: -0.0006287992882555, max: 0.0013178262928751\n",
      "head: 5a5, min: -2.197632969059047e-05, max: 8.41435496493026e-06\n"
     ]
    }
   ],
   "source": [
    "poly_heads = [\"3a0\",\"3a1\",\"3a2\",\"3a3\",\"4a0\",\"4a1\",\"4a2\",\"4a3\",\"4a4\",\"5a0\",\"5a1\",\"5a2\",\"5a3\",\"5a4\",\"5a5\"]\n",
    "for p in poly_heads:\n",
    "    print(\"head: \" + p + \", min: \" + str(all_df[p].min()) + \", max: \" + str(all_df[p].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "MX_min = -15\n",
    "MX_max = 15\n",
    "MY_min = 0\n",
    "MY_max = 40\n",
    "\n",
    "P_min = 95\n",
    "P_max = 121\n",
    "\n",
    "P_diff_min = -26\n",
    "P_diff_max = 26\n",
    "\n",
    "d_min = 20\n",
    "d_max = 40\n",
    "\n",
    "a0_min = -0.019\n",
    "a0_max = 0.014\n",
    "\n",
    "a1_min = -0.3\n",
    "a1_max = 0.22\n",
    "\n",
    "a2_min = -0.11\n",
    "a2_max = 0.17\n",
    "\n",
    "a3_min = -0.027\n",
    "a3_max = 0.016\n",
    "\n",
    "a4_min = -0.0007\n",
    "a4_max = 0.0014\n",
    "\n",
    "a5_min = -0.000023\n",
    "a5_max = 0.0000085\n",
    "\n",
    "norm_bounds = pd.DataFrame()\n",
    "for i in range(11):\n",
    "    norm_bounds[\"M\" + str(i) + \"X\"] = [MX_min, MX_max]\n",
    "    norm_bounds[\"M\" + str(i) + \"Y\"] = [MY_min, MY_max]\n",
    "\n",
    "for i in range(3):\n",
    "    norm_bounds[str(i+3) + \"a0\"] = [a0_min, a0_max]\n",
    "for i in range(3):\n",
    "    norm_bounds[str(i+3) + \"a1\"] = [a1_min, a1_max]\n",
    "for i in range(3):\n",
    "    norm_bounds[str(i+3) + \"a2\"] = [a2_min, a2_max]\n",
    "for i in range(3):\n",
    "    norm_bounds[str(i+3) + \"a3\"] = [a3_min, a3_max]\n",
    "for i in range(2):\n",
    "    norm_bounds[str(i+4) + \"a4\"] = [a4_min, a4_max]\n",
    "norm_bounds[\"5a5\"] = [a5_min, a5_max]\n",
    "norm_bounds[\"d\"] = [d_min, d_max]\n",
    "\n",
    "norm_bounds[\"M1-PL\"] = [P_min, P_max]\n",
    "norm_bounds[\"M1-PR\"] = [P_min, P_max]\n",
    "norm_bounds[\"M2-PL\"] = [P_min, P_max]\n",
    "norm_bounds[\"M2-PR\"] = [P_min, P_max]\n",
    "norm_bounds[\"M1-Diff\"] = [P_diff_min, P_diff_max]\n",
    "norm_bounds[\"M2-Diff\"] = [P_diff_min, P_diff_max]\n",
    "for i in range(lookback):\n",
    "    norm_bounds[\"M1-PL\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M1-PR\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M2-PL\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M2-PR\" + str(i)] = [P_min, P_max]\n",
    "    norm_bounds[\"M1-Diff\" + str(i)] = [P_diff_min, P_diff_max]\n",
    "    norm_bounds[\"M2-Diff\" + str(i)] = [P_diff_min, P_diff_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_bounds.to_csv(\"data/norm_bounds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_norm = all_df.copy()\n",
    "for c in norm_bounds:\n",
    "    min_val = norm_bounds.loc[0,c]\n",
    "    max_val = norm_bounds.loc[1,c]\n",
    "    all_df_norm[c] = (all_df_norm[c] - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_norm.to_csv(\"data/all_df_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
