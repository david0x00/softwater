{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from matplotlib import pyplot as plt\n",
    "from ipywidgets import interact\n",
    "plt.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_headers = [\"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext1\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext2\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext3\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module1_fullext4\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext1\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext2\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext3\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/module2_fullext4\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve1\",\n",
    "                \"/media/user1/Data 2000/soft_robotics_experiments/training_data/round_1/s_curve2\"]\n",
    "\n",
    "CSV_SFX = \".csv\"\n",
    "MARKERS_SFX = \"_markers\"\n",
    "POLY_SFX = \"_poly\"\n",
    "M10Y = \"M10Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466, 4, 4)\n",
      "(466, 7)\n",
      "(491, 4, 4)\n",
      "(491, 7)\n",
      "(496, 4, 4)\n",
      "(496, 7)\n",
      "(603, 4, 4)\n",
      "(603, 7)\n",
      "(585, 4, 4)\n",
      "(585, 7)\n",
      "(511, 4, 4)\n",
      "(511, 7)\n",
      "(425, 4, 4)\n",
      "(425, 7)\n",
      "(442, 4, 4)\n",
      "(442, 7)\n",
      "(269, 4, 4)\n",
      "(269, 7)\n",
      "(693, 4, 4)\n",
      "(693, 7)\n",
      "(234, 4, 4)\n",
      "(234, 7)\n",
      "(724, 4, 4)\n",
      "(724, 7)\n"
     ]
    }
   ],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "# The bigger the time step, the more the history. \n",
    "TIME_STEPS = 16\n",
    "SAMPLE_STEPS = 4\n",
    "\n",
    "x_labels = [\"M1-PL\", \"M1-PR\", \"M2-PL\", \"M2-PR\"]\n",
    "y_labels = [\"a0\", \"a1\", \"a2\", \"a3\", \"a4\", \"a5\", \"d\"]\n",
    "\n",
    "INPUT_DIM = len(x_labels)\n",
    "OUTPUT_DIM = len(y_labels)\n",
    "\n",
    "def get_index_groups(df):\n",
    "    return poly_df.groupby(poly_df.index.to_series().diff().ne(1).cumsum()).groups\n",
    "\n",
    "def expand_time_steps(data, time_steps, sample_steps):\n",
    "    entries = data.shape[0] - time_steps + 1\n",
    "    rows = int(time_steps / sample_steps)\n",
    "    cols = data.shape[1]\n",
    "    new_arr = np.zeros((entries, rows, cols))\n",
    "    for i in range(data.shape[0] - time_steps + 1):\n",
    "        full_arr = data.iloc[i:i + time_steps].to_numpy()\n",
    "        new_arr[i, :, :] = full_arr[sample_steps - 1::sample_steps]\n",
    "    return new_arr\n",
    "\n",
    "def normalize_2d(data):\n",
    "    min_vals = []\n",
    "    max_vals = []\n",
    "    rows = data.shape[0]\n",
    "    cols = data.shape[1]\n",
    "    for c in range(cols): \n",
    "        mx = data[0][c]\n",
    "        mn = mx\n",
    "        for r in range(rows):\n",
    "            val = data[r][c]\n",
    "            if val > mx:\n",
    "                mx = val\n",
    "            if val < mn:\n",
    "                mn = val\n",
    "        min_vals.append(mn)\n",
    "        max_vals.append(mx)\n",
    "        for r in range(rows):\n",
    "            val = data[r][c]\n",
    "            data[r][c] = (val - mn) / (mx - mn)\n",
    "    return min_vals, max_vals\n",
    "    \n",
    "def normalize_3d(data):\n",
    "    min_vals = []\n",
    "    max_vals = []\n",
    "    entries = data.shape[0]\n",
    "    rows = data.shape[1]\n",
    "    cols = data.shape[2]\n",
    "    for c in range(cols):\n",
    "        mx = data[0][0][c]\n",
    "        mn = mx\n",
    "        for e in range(entries):\n",
    "            for r in range(rows):\n",
    "                val = data[e][r][c]\n",
    "                if val > mx:\n",
    "                    mx = val\n",
    "                if val < mn:\n",
    "                    mn = val\n",
    "        min_vals.append(mn)\n",
    "        max_vals.append(mx)\n",
    "        for e in range(entries):\n",
    "            for r in range(rows):\n",
    "                val = data[e][r][c]\n",
    "                data[e][r][c] = (val - mn) / (mx - mn)\n",
    "    return min_vals, max_vals\n",
    "\n",
    "for header in file_headers:\n",
    "    data_file = header + CSV_SFX\n",
    "    marker_file = header + MARKERS_SFX + CSV_SFX\n",
    "    poly_file = header + POLY_SFX + CSV_SFX\n",
    "    \n",
    "    data_df = pd.read_csv(data_file)\n",
    "    marker_df = pd.read_csv(marker_file)\n",
    "    poly_df = pd.read_csv(poly_file)\n",
    "    \n",
    "    # NOTE: Handle when the robot goes out of frame.\n",
    "    zero_indices = list(marker_df[marker_df[M10Y] == 0].index)\n",
    "    \n",
    "    data_df = data_df.drop(data_df.index[zero_indices])\n",
    "    poly_df = poly_df.drop(poly_df.index[zero_indices])\n",
    "    \n",
    "    data_groups = get_index_groups(data_df)\n",
    "    poly_groups = get_index_groups(poly_df)\n",
    "    \n",
    "    for dg in data_groups:\n",
    "        idx_list = data_groups[dg]\n",
    "        sub_data_df = data_df.loc[idx_list[0]:idx_list[-1]+1, x_labels]\n",
    "        sub_poly_df = poly_df.loc[idx_list[0]:idx_list[-1]+1, y_labels]\n",
    "        \n",
    "        sub_data_df_exp = expand_time_steps(sub_data_df, TIME_STEPS, SAMPLE_STEPS)\n",
    "        sub_poly_df_exp = sub_poly_df[TIME_STEPS-1:]\n",
    "        \n",
    "        print(sub_data_df_exp.shape)\n",
    "        print(sub_poly_df_exp.shape)\n",
    "        \n",
    "        x_list.append(sub_data_df_exp)\n",
    "        y_list.append(sub_poly_df_exp.to_numpy())\n",
    "        \n",
    "x_data = np.concatenate(x_list, axis=0)\n",
    "y_data = np.concatenate(y_list, axis=0)\n",
    "\n",
    "x_mins, x_maxes = normalize_3d(x_data)\n",
    "y_mins, y_maxes = normalize_2d(y_data)\n",
    "\n",
    "x_data_shuffled, y_data_shuffled = sklearn.utils.shuffle(x_data, y_data)\n",
    "\n",
    "data_length = len(x_data_shuffled)\n",
    "split_percent = 0.8\n",
    "train_test_split = int(data_length * split_percent)\n",
    "\n",
    "x_train = x_data_shuffled[:train_test_split]\n",
    "y_train = y_data_shuffled[:train_test_split]\n",
    "\n",
    "x_test = x_data_shuffled[train_test_split:]\n",
    "y_test = y_data_shuffled[train_test_split:]\n",
    "\n",
    "INPUT_TIME_STEPS = x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4751, 4, 4)\n",
      "(1188, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "# Have to take TIME_STEPS off the top of *every* run. Not just them all together.\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 64)                17664     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 24,551\n",
      "Trainable params: 24,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(LSTM(64, input_shape=(INPUT_TIME_STEPS, INPUT_DIM), activation='relu', return_sequences=True))\n",
    "model.add(LSTM(64, input_shape=(INPUT_TIME_STEPS, INPUT_DIM), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(OUTPUT_DIM, activation='relu'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.1064 - accuracy: 0.4872\n",
      "Epoch 2/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0169 - accuracy: 0.6270\n",
      "Epoch 3/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0116 - accuracy: 0.6946\n",
      "Epoch 4/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0097 - accuracy: 0.7229\n",
      "Epoch 5/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0084 - accuracy: 0.7536\n",
      "Epoch 6/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0080 - accuracy: 0.7495\n",
      "Epoch 7/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0074 - accuracy: 0.7409\n",
      "Epoch 8/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0069 - accuracy: 0.7562\n",
      "Epoch 9/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0065 - accuracy: 0.7728\n",
      "Epoch 10/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0063 - accuracy: 0.7787\n",
      "Epoch 11/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.7737\n",
      "Epoch 12/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0061 - accuracy: 0.7710\n",
      "Epoch 13/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0059 - accuracy: 0.7770\n",
      "Epoch 14/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0055 - accuracy: 0.7762\n",
      "Epoch 15/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0054 - accuracy: 0.7912\n",
      "Epoch 16/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0056 - accuracy: 0.7747\n",
      "Epoch 17/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.7879\n",
      "Epoch 18/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.7872\n",
      "Epoch 19/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0053 - accuracy: 0.7778\n",
      "Epoch 20/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0049 - accuracy: 0.7852\n",
      "Epoch 21/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.8011\n",
      "Epoch 22/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.7722\n",
      "Epoch 23/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.7959\n",
      "Epoch 24/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.7893\n",
      "Epoch 25/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.7935\n",
      "Epoch 26/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.7927\n",
      "Epoch 27/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.7963\n",
      "Epoch 28/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0047 - accuracy: 0.7883\n",
      "Epoch 29/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.8004\n",
      "Epoch 30/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.7906\n",
      "Epoch 31/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.7975\n",
      "Epoch 32/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 0.7998\n",
      "Epoch 33/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.7812\n",
      "Epoch 34/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.8058\n",
      "Epoch 35/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0048 - accuracy: 0.7899\n",
      "Epoch 36/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0046 - accuracy: 0.8131\n",
      "Epoch 37/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.7893\n",
      "Epoch 38/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.7988\n",
      "Epoch 39/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.7916\n",
      "Epoch 40/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.7975\n",
      "Epoch 41/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.7944\n",
      "Epoch 42/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0045 - accuracy: 0.7878\n",
      "Epoch 43/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.8093\n",
      "Epoch 44/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.7888\n",
      "Epoch 45/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.7993\n",
      "Epoch 46/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0044 - accuracy: 0.7913\n",
      "Epoch 47/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0042 - accuracy: 0.7841\n",
      "Epoch 48/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.8114\n",
      "Epoch 49/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0043 - accuracy: 0.7907\n",
      "Epoch 50/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.8034\n",
      "Epoch 51/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.7993\n",
      "Epoch 52/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0041 - accuracy: 0.7855\n",
      "Epoch 53/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.8049\n",
      "Epoch 54/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.7934\n",
      "Epoch 55/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8018\n",
      "Epoch 56/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.7968\n",
      "Epoch 57/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8060\n",
      "Epoch 58/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8078\n",
      "Epoch 59/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8076\n",
      "Epoch 60/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.7989\n",
      "Epoch 61/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.7871\n",
      "Epoch 62/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.7991\n",
      "Epoch 63/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8118\n",
      "Epoch 64/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8074\n",
      "Epoch 65/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8027\n",
      "Epoch 66/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0040 - accuracy: 0.8161\n",
      "Epoch 67/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8036\n",
      "Epoch 68/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8033\n",
      "Epoch 69/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8007\n",
      "Epoch 70/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8140\n",
      "Epoch 71/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8048\n",
      "Epoch 72/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.7976\n",
      "Epoch 73/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.7982\n",
      "Epoch 74/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8031\n",
      "Epoch 75/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.7945\n",
      "Epoch 76/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8138\n",
      "Epoch 77/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.7990\n",
      "Epoch 78/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8112\n",
      "Epoch 79/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8073\n",
      "Epoch 80/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8090\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8042\n",
      "Epoch 82/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.7973\n",
      "Epoch 83/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8044\n",
      "Epoch 84/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8055\n",
      "Epoch 85/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.8019\n",
      "Epoch 86/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8043\n",
      "Epoch 87/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.7998\n",
      "Epoch 88/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8002\n",
      "Epoch 89/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.7996\n",
      "Epoch 90/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8099\n",
      "Epoch 91/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8126\n",
      "Epoch 92/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8117\n",
      "Epoch 93/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8091\n",
      "Epoch 94/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8021\n",
      "Epoch 95/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8173\n",
      "Epoch 96/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8001\n",
      "Epoch 97/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8128\n",
      "Epoch 98/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8121\n",
      "Epoch 99/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8107\n",
      "Epoch 100/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.7960\n",
      "Epoch 101/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8010\n",
      "Epoch 102/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8131\n",
      "Epoch 103/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8215\n",
      "Epoch 104/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.8119\n",
      "Epoch 105/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8121\n",
      "Epoch 106/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8213\n",
      "Epoch 107/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.7984\n",
      "Epoch 108/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8100\n",
      "Epoch 109/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8148\n",
      "Epoch 110/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8096\n",
      "Epoch 111/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8120\n",
      "Epoch 112/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8085\n",
      "Epoch 113/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8204\n",
      "Epoch 114/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8089\n",
      "Epoch 115/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8100\n",
      "Epoch 116/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8213\n",
      "Epoch 117/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8104\n",
      "Epoch 118/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8042\n",
      "Epoch 119/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8118\n",
      "Epoch 120/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8102\n",
      "Epoch 121/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0038 - accuracy: 0.7991\n",
      "Epoch 122/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8177\n",
      "Epoch 123/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8172\n",
      "Epoch 124/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8272\n",
      "Epoch 125/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8108\n",
      "Epoch 126/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8124\n",
      "Epoch 127/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8061\n",
      "Epoch 128/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8132\n",
      "Epoch 129/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8032\n",
      "Epoch 130/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8121\n",
      "Epoch 131/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8289\n",
      "Epoch 132/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8063\n",
      "Epoch 133/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8096\n",
      "Epoch 134/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8120\n",
      "Epoch 135/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8047\n",
      "Epoch 136/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8110\n",
      "Epoch 137/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8174\n",
      "Epoch 138/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8097\n",
      "Epoch 139/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8158\n",
      "Epoch 140/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8129\n",
      "Epoch 141/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8181\n",
      "Epoch 142/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8168\n",
      "Epoch 143/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8142\n",
      "Epoch 144/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8165\n",
      "Epoch 145/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8166\n",
      "Epoch 146/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8280\n",
      "Epoch 147/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.7975\n",
      "Epoch 148/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8298\n",
      "Epoch 149/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8165\n",
      "Epoch 150/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8119\n",
      "Epoch 151/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8191\n",
      "Epoch 152/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8267\n",
      "Epoch 153/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8150\n",
      "Epoch 154/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8215\n",
      "Epoch 155/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8186\n",
      "Epoch 156/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8265\n",
      "Epoch 157/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8195\n",
      "Epoch 158/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8177\n",
      "Epoch 159/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8212\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.8150\n",
      "Epoch 161/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8209\n",
      "Epoch 162/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8162\n",
      "Epoch 163/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8062\n",
      "Epoch 164/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8135\n",
      "Epoch 165/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.8148\n",
      "Epoch 166/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8117\n",
      "Epoch 167/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8136\n",
      "Epoch 168/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8154\n",
      "Epoch 169/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8128\n",
      "Epoch 170/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8158\n",
      "Epoch 171/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8024\n",
      "Epoch 172/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.7981\n",
      "Epoch 173/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8189\n",
      "Epoch 174/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8151\n",
      "Epoch 175/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8005\n",
      "Epoch 176/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.8112\n",
      "Epoch 177/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8223\n",
      "Epoch 178/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8267\n",
      "Epoch 179/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8068\n",
      "Epoch 180/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8171\n",
      "Epoch 181/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8269\n",
      "Epoch 182/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8191\n",
      "Epoch 183/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8035\n",
      "Epoch 184/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8152\n",
      "Epoch 185/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8113\n",
      "Epoch 186/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8271\n",
      "Epoch 187/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8174\n",
      "Epoch 188/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8146\n",
      "Epoch 189/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8125\n",
      "Epoch 190/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8185\n",
      "Epoch 191/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8147\n",
      "Epoch 192/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8193\n",
      "Epoch 193/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8145\n",
      "Epoch 194/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8140\n",
      "Epoch 195/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8162\n",
      "Epoch 196/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8178\n",
      "Epoch 197/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8278\n",
      "Epoch 198/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8194\n",
      "Epoch 199/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8183\n",
      "Epoch 200/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8134\n",
      "Epoch 201/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8144\n",
      "Epoch 202/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8217\n",
      "Epoch 203/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8195\n",
      "Epoch 204/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8206\n",
      "Epoch 205/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8054\n",
      "Epoch 206/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8277\n",
      "Epoch 207/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8232\n",
      "Epoch 208/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.8250\n",
      "Epoch 209/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8187\n",
      "Epoch 210/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8186\n",
      "Epoch 211/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8185\n",
      "Epoch 212/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8228\n",
      "Epoch 213/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8174\n",
      "Epoch 214/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8215\n",
      "Epoch 215/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8180\n",
      "Epoch 216/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8235\n",
      "Epoch 217/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8236\n",
      "Epoch 218/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8149\n",
      "Epoch 219/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8231\n",
      "Epoch 220/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8223\n",
      "Epoch 221/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8136\n",
      "Epoch 222/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8294\n",
      "Epoch 223/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8096\n",
      "Epoch 224/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8012\n",
      "Epoch 225/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8142\n",
      "Epoch 226/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8206\n",
      "Epoch 227/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8173\n",
      "Epoch 228/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8163\n",
      "Epoch 229/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8088\n",
      "Epoch 230/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8216\n",
      "Epoch 231/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8279\n",
      "Epoch 232/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8197\n",
      "Epoch 233/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8237\n",
      "Epoch 234/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8178\n",
      "Epoch 235/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8240\n",
      "Epoch 236/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8305\n",
      "Epoch 237/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.8104\n",
      "Epoch 238/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8089\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8211\n",
      "Epoch 240/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8197\n",
      "Epoch 241/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8142\n",
      "Epoch 242/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8112\n",
      "Epoch 243/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8178\n",
      "Epoch 244/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8183\n",
      "Epoch 245/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8306\n",
      "Epoch 246/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8406\n",
      "Epoch 247/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8270\n",
      "Epoch 248/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8210\n",
      "Epoch 249/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8135\n",
      "Epoch 250/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8178\n",
      "Epoch 251/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8173\n",
      "Epoch 252/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8089\n",
      "Epoch 253/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8095\n",
      "Epoch 254/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.8245\n",
      "Epoch 255/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8091\n",
      "Epoch 256/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8205\n",
      "Epoch 257/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8145\n",
      "Epoch 258/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8121\n",
      "Epoch 259/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8251\n",
      "Epoch 260/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8059\n",
      "Epoch 261/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8202\n",
      "Epoch 262/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8120\n",
      "Epoch 263/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8090\n",
      "Epoch 264/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8088\n",
      "Epoch 265/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8208\n",
      "Epoch 266/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8088\n",
      "Epoch 267/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8199\n",
      "Epoch 268/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8262\n",
      "Epoch 269/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8126\n",
      "Epoch 270/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8112\n",
      "Epoch 271/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8265\n",
      "Epoch 272/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8020\n",
      "Epoch 273/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8138\n",
      "Epoch 274/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8092\n",
      "Epoch 275/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8149\n",
      "Epoch 276/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8219\n",
      "Epoch 277/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8183\n",
      "Epoch 278/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8247\n",
      "Epoch 279/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8306\n",
      "Epoch 280/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8062\n",
      "Epoch 281/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8200\n",
      "Epoch 282/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.8172\n",
      "Epoch 283/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8186\n",
      "Epoch 284/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8278\n",
      "Epoch 285/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8212\n",
      "Epoch 286/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8245\n",
      "Epoch 287/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.8127\n",
      "Epoch 288/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8220\n",
      "Epoch 289/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8130\n",
      "Epoch 290/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8096\n",
      "Epoch 291/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8246\n",
      "Epoch 292/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8125\n",
      "Epoch 293/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8097\n",
      "Epoch 294/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8196\n",
      "Epoch 295/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8232\n",
      "Epoch 296/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8106\n",
      "Epoch 297/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8091\n",
      "Epoch 298/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.8208\n",
      "Epoch 299/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.8228\n",
      "Epoch 300/300\n",
      "594/594 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.8074\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 300\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 588us/step - loss: 0.0011 - accuracy: 0.8729\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(history.history[\"loss\"], open(\"objects/rnn_loss.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_output(y):\n",
    "    ret = []\n",
    "    for i in range(len(y)):\n",
    "        max_val = y_maxes[i]\n",
    "        min_val = y_mins[i]\n",
    "        val = y[i]\n",
    "        rescaled_val = (val * (max_val - min_val)) + min_val\n",
    "        ret.append(rescaled_val)\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4c76963d444f89b00a968326a26ff0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.evaluate_poly(idx=(0, 1187, 1))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tests = len(x_test)\n",
    "def evaluate_poly(idx=(0,num_tests-1,1)):\n",
    "    x_select = np.expand_dims(x_test[idx], axis=0)\n",
    "    #x_select = np.array(x_test.loc[index, :]).reshape(1, -1)\n",
    "    y_pred = model.predict(x_select)\n",
    "    y_pred = rescale_output(y_pred[0])\n",
    "    a_pred = np.flip(y_pred[:-1])\n",
    "    d_pred = y_pred[-1]\n",
    "    \n",
    "    y_select = y_test[idx]\n",
    "    y_select = rescale_output(y_select)\n",
    "    a_select = np.flip(y_select[:-1])\n",
    "    d_select = y_select[-1]\n",
    "    \n",
    "    print(d_pred, d_select)\n",
    "    \n",
    "    poly_pred = np.poly1d(a_pred)\n",
    "    poly_select = np.poly1d(a_select)\n",
    "    \n",
    "    yp = np.linspace(0, d_pred)\n",
    "    xp = poly_pred(yp)\n",
    "    \n",
    "    ys = np.linspace(0, d_select)\n",
    "    xs = poly_select(ys)\n",
    "    \n",
    "    plt.plot(xs, ys)\n",
    "    plt.plot(xp, yp)\n",
    "    plt.xlim([-20,20])\n",
    "    plt.ylim([-1,39])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "interact(evaluate_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 8])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5,6,7,8])\n",
    "a[3::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/first_rnn/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"./models/first_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
